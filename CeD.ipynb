{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2023-12-28T13:25:00.673149Z",
     "start_time": "2023-12-28T13:24:47.337070Z"
    }
   },
   "outputs": [],
   "source": [
    "import bs4\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from urllib.request import urlopen as uReq"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "61ed8c0fbde6adb1"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as soup"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5a38b4cedab12ce9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_list = list()\n",
    "author_list = list()\n",
    "date_list = list()\n",
    "replies_list = list()\n",
    "stats_list = list()\n",
    "forum_page_list = list()\n",
    "page_topic_count_list = list()\n",
    "topic_url_list = list()\n",
    "firstposts_list = list()\n",
    "initial_post_username_list = list()\n",
    "initial_post_date_list = list()\n",
    "from datetime import datetime\n",
    "topic_by_author = pd.DataFrame()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "79f2cd9801c23be4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "my_url = f'https://www.celiac.com/forums/forum/13-celiac-disease-pre-diagnosis-testing-symptoms/page/3/?sortby=start_date&sortdirection=desc'\n",
    "uClient = uReq(my_url)\n",
    "page_html = uClient.read()\n",
    "uClient.close()\n",
    "page_soup = soup(page_html, \"html.parser\")\n",
    "final_page = int(page_soup.find(\"li\",{\"class\":\"ipsPagination_last\"}).a.get(\"data-page\"))"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "59ca1e1193bdfe9c"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_page = 53\n",
    "final_page = 103\n",
    "end_page = final_page+1\n",
    "total_pages_evaluated = 0\n",
    "for forum_page in range(start_page,end_page):\n",
    "    my_url = f'https://www.celiac.com/forums/forum/13-celiac-disease-pre-diagnosis-testing-symptoms/page/{forum_page}/?sortby=start_date&sortdirection=desc'\n",
    "    uClient = uReq(my_url)\n",
    "    page_html = uClient.read()\n",
    "    uClient.close()\n",
    "    page_soup = soup(page_html, \"html.parser\")\n",
    "    \n",
    "    topic_containers =  page_soup.findAll(\"span\",{\"class\":\"ipsType_break ipsContained\"})\n",
    "    author_containers = page_soup.findAll(\"div\",{\"class\":\"ipsDataItem_meta ipsType_reset ipsType_light ipsType_blendLinks\"})\n",
    "    datetime_containers = page_soup.findAll(\"a\",{\"class\":\"ipsType_blendLinks\"})\n",
    "    replies_containers = page_soup.findAll(\"li\",{\"data-stattype\":\"forums_comments\"}) #renamed to comments since this includes original post as well as replies.\n",
    "    span_containers = page_soup.findAll(\"span\",{\"class\":\"ipsType_break ipsContained\"})\n",
    "    num_views_containers = page_soup.findAll(\"li\",{\"data-stattype\":\"num_views\"})\n",
    "    \n",
    "    \n",
    "    page_topic_count = 0\n",
    "    for topic_container, topic_url_container, author_container, replies_container, num_views_container, datetime_container in zip(topic_containers, topic_containers, author_containers, replies_containers, num_views_containers, datetime_containers):\n",
    "       \n",
    "        topic = topic_container.text.strip()\n",
    "        author = author_container.a.text.strip()\n",
    "        datestr = datetime_container.time.text.strip()\n",
    "        \n",
    "        replies_str = replies_container.span.text.strip()\n",
    "        replies_k = replies_str.__contains__('k')\n",
    "        replies = int(float(replies_str.replace('k',''))*1000) if replies_k else int(float(replies_str))\n",
    "        \n",
    "        num_views_str = num_views_container.span.text.strip()\n",
    "        num_views_k = num_views_str.__contains__('k')\n",
    "        num_views = int(float(num_views_str.replace('k',''))*1000) if num_views_k else int(float(num_views_str))\n",
    "        \n",
    "        topic_url = topic_url_container.find(\"a\").get(\"href\")\n",
    "        \n",
    "        #below sourced from chatGPT\n",
    "        try:\n",
    "            # Try parsing with year (%Y) format\n",
    "            date_obj = datetime.strptime(datestr, '%B %d, %Y')\n",
    "        except ValueError:\n",
    "            # If year is not present, add a default year\n",
    "            date_obj = datetime.strptime(datestr + ', 2023', '%B %d, %Y')\n",
    "        #above sourced from chatGPT\n",
    "    \n",
    "\n",
    "        uClient2 = uReq(topic_url)\n",
    "        page_html2 = uClient2.read()\n",
    "        uClient2.close()\n",
    "        page_soup2 = soup(page_html2, \"html.parser\")\n",
    "        posts = page_soup2.findAll(\"div\",{\"class\":\"cPost_contentWrap\"})\n",
    "        initial_post_p = posts[0].find_all('p')\n",
    "        initial_post = ' '.join([text.get_text(strip=True) for text in initial_post_p])\n",
    "        initial_post_username = page_soup2.find(\"p\",{\"class\":\"ipsType_reset ipsType_blendLinks\"}).a.text\n",
    "        initial_post_dt = page_soup2.find(\"p\",{\"class\":\"ipsType_reset ipsType_blendLinks\"}).time.get(\"datetime\")[0:10]\n",
    "        initial_post_dt_format = datetime.strptime(initial_post_dt, '%Y-%m-%d')\n",
    "        initial_post_date = initial_post_dt_format.date()\n",
    "\n",
    "        \n",
    "        last_updated = date_obj.strftime('%Y-%m-%d') #chatgpt\n",
    "        print(forum_page, end=\" | \")     \n",
    "        print(topic, end=\" | \")\n",
    "        print(author, end=\" | \")\n",
    "        print(last_updated, end=\" | \")\n",
    "        print(f\"{replies_str} replies | {num_views} views\")\n",
    "        \n",
    "        topic_list.append(topic)\n",
    "        author_list.append(author)\n",
    "        date_list.append(last_updated)\n",
    "        forum_page_list.append(forum_page)\n",
    "        replies_list.append(replies)\n",
    "        stats_list.append(num_views)\n",
    "        topic_url_list.append(topic_url)\n",
    "        \n",
    "        firstposts_list.append(initial_post)\n",
    "        initial_post_username_list.append(initial_post_username)\n",
    "        initial_post_date_list.append(initial_post_date)\n",
    "    \n",
    "        page_topic_count=page_topic_count+1\n",
    "        \n",
    "    topic_by_author = pd.DataFrame(list(zip(forum_page_list, topic_list, initial_post_username_list, author_list, replies_list, stats_list, initial_post_date_list, date_list, topic_url_list, firstposts_list)), columns =['Forum Page','Topic', 'Initial Author','Author', 'Replies', 'Stats List', 'Started', 'Last Updated', 'URL', 'First Post'])\n",
    "    page_topic_count_list.append(page_topic_count)\n",
    "    total_pages_evaluated=total_pages_evaluated+1"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aced6569ee33fb26"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_by_author_3_to_103 = topic_by_author\n",
    "\n",
    "# Exporting DataFrame to CSV\n",
    "topic_by_author_3_to_103.to_csv('celiac_com_forum_13_p3to103.csv', index=False)  # Exporting to CSV without row indices\n",
    "\n",
    "# Exporting DataFrame to Excel (XLSX)\n",
    "topic_by_author_3_to_103.to_excel('celiac_com_forum_13_p3to103.xlsx', index=False)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "35634e230c4cc4b5"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "# Get the value of 'href' attribute\n",
    "uClient2 = uReq('https://www.celiac.com/forums/topic/158655-25-years-old-15-yearof-testing-accurate-blood-tests-and-symptoms/')\n",
    "page_html2 = uClient2.read()\n",
    "uClient2.close()\n",
    "page_soup2 = soup(page_html2, \"html.parser\")\n",
    "posts = page_soup2.findAll(\"div\",{\"data-role\":\"commentContent\"})\n",
    "initial_post = posts[0].find_all('p')\n",
    "extracted_text = ' '.join([text.get_text(strip=True) for text in initial_post])\n",
    "initial_post_username = page_soup2.find(\"p\",{\"class\":\"ipsType_reset ipsType_blendLinks\"}).a.text\n",
    "initial_post_dt = page_soup2.find(\"p\",{\"class\":\"ipsType_reset ipsType_blendLinks\"}).time.get(\"datetime\")[0:10]\n",
    "initial_post_dt_format = datetime.strptime(initial_post_dt, '%Y-%m-%d')\n",
    "initial_post_date = initial_post_dt_format.date()\n",
    "#print(posts)\n",
    "print(extracted_text)\n",
    "#firstposts_list.append(initial_post)\n",
    "#initial_post_username_list.append(initial_post_username)\n",
    "#initial_post_date_list.append(initial_post_date)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3fd97e682ff1f689"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_by_author_3_to_103.iloc[:,9]"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "15ad37322210b4d9"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "topic_url_list"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2f03bc55e3b4ce31"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "print(initial_post_username)\n",
    "print(initial_post_date_dt.date())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6ef0e31ac5be9102"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
